{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Regularization\n",
    "\n",
    "A) Use the Boston dataset, and use Ridge regression model with tuning parameter set to 100 (alpha =100). Find the $R^2$ score and number of non zero coefficients.\n",
    "\n",
    "B) Use Lasso regression instead of Ridge regression, also set the tuning parameter to 100. Find the $R^2$ score and number of non zero coefficients.\n",
    "\n",
    "C) Change the tuning parameter of the Lasso model to a very low value (alpha =0.001). What is the $R^2$ score.\n",
    "\n",
    "D) Comment on your result. In this problem, do all feature seem important in making predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.chegg.com/homework-help/definitions/predicted-value-y-hat-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name='JiayuChen'\n",
    "pittID='jic117'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "\n",
    "dataset = load_boston()\n",
    "X=dataset.data\n",
    "Y=dataset.target\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X, Y, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A) R_square score is: 0.592535803616\n",
      "The number of non zero coefficients: 13\n"
     ]
    }
   ],
   "source": [
    "# A\n",
    "RidgeModel=Ridge(alpha=100).fit(X_train, Y_train)\n",
    "R_squareA = RidgeModel.score(X_test,Y_test)\n",
    "non_zeroA=np.sum(RidgeModel.coef_!=0)\n",
    "print('A) R_square score is:', R_squareA)\n",
    "print('The number of non zero coefficients:', non_zeroA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B) R_square score is: 0.118669161755\n",
      "The number of non zero coefficients: 2\n"
     ]
    }
   ],
   "source": [
    "# B\n",
    "LassoModel=Lasso(alpha=100).fit(X_train, Y_train)\n",
    "R_squareB=LassoModel.score(X_test,Y_test)\n",
    "non_zero=np.sum(LassoModel.coef_!=0)\n",
    "print('B) R_square score is:', R_squareB)\n",
    "print('The number of non zero coefficients:',non_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C) R_square score is: 0.635035312517\n"
     ]
    }
   ],
   "source": [
    "# C\n",
    "LassoModel=Lasso(alpha=.001). fit(X_train, Y_train)\n",
    "R_squareB=LassoModel.score(X_test,Y_test)\n",
    "non_zero=np.sum(LassoModel.coef_!=0)\n",
    "print('C) R_square score is:', R_squareB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D) Yes, all features seems important in making predictions.\n",
    "If the value of alpha is relatively large, the accuracy will be lower.\n",
    "When all features are included in the response, ridge is a better model. But when fewer features are included, lasso model performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Logistic Regression\n",
    "\n",
    "In this exercise, you will use logistic regression to classify breast cancer as malignant or benign using the sklearn data set. Run the code below to print and read the description of the data set. Use logistic regression, with Lasso regularization (penelty =l1) and the default regularization parameter to build the classifier. What is the accuracy?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])\n",
      "The Accuracy is 0.958041958042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np\n",
    "\n",
    "DataCancer=load_breast_cancer()\n",
    "print(DataCancer.keys())\n",
    "# print(DataCancer.DESCR)\n",
    "\n",
    "X_features=DataCancer.data\n",
    "Y_targetClass=DataCancer.target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X_features, Y_targetClass, random_state= 0)\n",
    "LogRegModel=LogisticRegression(penalty=\"l1\")\n",
    "fitted_model=LogRegModel.fit(X_train, Y_train)\n",
    "accuracy=LogRegModel.score(X_test, Y_test)\n",
    "\n",
    "print('The Accuracy is', accuracy)\n",
    "X_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
